'use client';
import { useState } from 'react';

export const Recorder = ({ onText }: { onText: (text: string) => void }) => {
  const [isRecording,setIsRecording] = useState(false);

  const startRecognition = () => {
    const SpeechRecognition =
      (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;

    if (!SpeechRecognition) {
      alert('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = 'ja-JP';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.onresult = (event: any) => {
      const text = event.results[0][0].transcript;
      console.log('éŸ³å£°èªè­˜çµæœ:', text);
      onText(text);
    };

recognition.onerror = (event: any) => {
  console.error('ğŸ¤ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', event.error);

  switch (event.error) {
    case 'aborted':
      alert('éŸ³å£°èªè­˜ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚');
      break;
    case 'not-allowed':
      alert('ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      break;
    case 'audio-capture':
      alert('ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¥ç¶šã‚’ã”ç¢ºèªãã ã•ã„ã€‚');
      break;
    case 'network':
      alert('ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚ŠéŸ³å£°èªè­˜ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚');
      break;
    case 'no-speech':
      alert('éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©±ã—ã¦ãã ã•ã„ã€‚');
      break;
    default:
      alert(`éŸ³å£°èªè­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${event.error}`);
  }
};

    recognition.onend = () => {
      console.log('éŸ³å£°èªè­˜çµ‚äº†');
      setIsRecording(false);
    };

    recognition.start();
    setIsRecording(true);
    console.log('éŸ³å£°èªè­˜é–‹å§‹');
  };

  return (
{isRecording ? "éŒ²éŸ³ä¸­...":"åœæ­¢ä¸­"}
    <button
      onClick={startRecognition}
      className="text-sm bg-green-600 text-white px-3 py-1 rounded"
    >
      ğŸ™ éŸ³å£°ã§å›ç­”
    </button>
  );
};
